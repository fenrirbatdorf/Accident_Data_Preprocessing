{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43884252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee171a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dr Olsen Preprocessing version\n",
    "\n",
    "def control_train_class_merge(df):\n",
    "    cols = ['Distance(mi)', 'Street', 'Temperature(F)', 'Humidity(%)',\n",
    "            'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Weather_Condition',\n",
    "            'Amenity', 'Crossing', 'Junction', 'Railway', 'Station', 'Stop',\n",
    "            'Traffic_Calming', 'Traffic_Signal', 'Sunrise_Sunset']\n",
    "\n",
    "    df['Class'] = np.where(df['Severity'] == 1, 1, 0)\n",
    "    df_c1 = df[df['Class'] != 0]\n",
    "    df_c0 = df[df['Class'] != 1]\n",
    "    df_c1 = df_c1.drop_duplicates()\n",
    "    df_c0 = df_c0.drop_duplicates()\n",
    "    df_c1.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/control_datasets_unbin/Control_Class_Merge/control_class1.csv\", columns = cols, index = False)\n",
    "    df_c0.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/control_datasets_unbin/Control_Class_Merge/control_class234_merge.csv\", columns = cols, index = False)\n",
    "\n",
    "    df['Class'] = np.where(df['Severity'] == 2, 1, 0)\n",
    "    df_c1 = df[df['Class'] != 0]\n",
    "    df_c0 = df[df['Class'] != 1]\n",
    "    df_c1 = df_c1.drop_duplicates()\n",
    "    df_c0 = df_c0.drop_duplicates()\n",
    "    df_c1.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/control_datasets_unbin/Control_Class_Merge/control_class2.csv\", columns = cols, index = False)\n",
    "    df_c0.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/control_datasets_unbin/Control_Class_Merge/control_class134_merge.csv\", columns = cols, index = False)\n",
    "\n",
    "    df['Class'] = np.where(df['Severity'] == 3, 1, 0)\n",
    "    df_c1 = df[df['Class'] != 0]\n",
    "    df_c0 = df[df['Class'] != 1]\n",
    "    df_c1 = df_c1.drop_duplicates()\n",
    "    df_c0 = df_c0.drop_duplicates()\n",
    "    df_c1.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/control_datasets_unbin/Control_Class_Merge/control_class3.csv\", columns = cols, index = False)\n",
    "    df_c0.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/control_datasets_unbin/Control_Class_Merge/control_class124_merge.csv\", columns = cols, index = False)\n",
    "\n",
    "    df['Class'] = np.where(df['Severity'] == 4, 1, 0)\n",
    "    df_c1 = df[df['Class'] != 0]\n",
    "    df_c0 = df[df['Class'] != 1]\n",
    "    df_c1 = df_c1.drop_duplicates()\n",
    "    df_c0 = df_c0.drop_duplicates()\n",
    "    df_c1.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/control_datasets_unbin/Control_Class_Merge/control_class4.csv\", columns = cols, index = False)\n",
    "    df_c0.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/control_datasets_unbin/Control_Class_Merge/control_class123_merge.csv\", columns = cols, index = False)\n",
    "    \n",
    "    df = df.drop(columns = 'Class')\n",
    "    return df\n",
    "\n",
    "# DO NOT RUN WITH TEST DATA CLEANING\n",
    "#df = control_train_class_merge(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc76684e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fenrir processing version\n",
    "# Function to break apart and export all one vs many variations of the dataset\n",
    "\n",
    "def feat_eng_train_class_merge(df):\n",
    "    cols = ['Distance(mi)', 'County', 'Amenity', 'Bump', 'Crossing', 'Give_Way',\n",
    "       'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop',\n",
    "       'Traffic_Calming', 'Traffic_Signal', 'Sunrise_Sunset',\n",
    "       'Season', 'Snow_Ice', 'Low_Vis_Weather', 'Rainy', 'Qty_Slowing_Elements', \n",
    "       'Freezing']\n",
    "    df['Class'] = np.where(df['Severity'] == 1, 1, 0)\n",
    "    df_c1 = df[df['Class'] != 0]\n",
    "    df_c0 = df[df['Class'] != 1]\n",
    "    df_c1 = df_c1.drop_duplicates()\n",
    "    df_c0 = df_c0.drop_duplicates()\n",
    "    df_c1.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/feat_eng_datasets_unbin/Feat_Eng_Merge/feat_eng_class1.csv\", columns = cols, index = False)\n",
    "    df_c0.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/feat_eng_datasets_unbin/Feat_Eng_Merge/feat_eng_class234_merge.csv\", columns = cols, index = False)\n",
    "\n",
    "    df['Class'] = np.where(df['Severity'] == 2, 1, 0)\n",
    "    df_c1 = df[df['Class'] != 0]\n",
    "    df_c0 = df[df['Class'] != 1]\n",
    "    df_c1 = df_c1.drop_duplicates()\n",
    "    df_c0 = df_c0.drop_duplicates()\n",
    "    df_c1.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/feat_eng_datasets_unbin/Feat_Eng_Merge/feat_eng_class2.csv\", columns = cols, index = False)\n",
    "    df_c0.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/feat_eng_datasets_unbin/Feat_Eng_Merge/feat_eng_class134_merge.csv\", columns = cols, index = False)\n",
    "\n",
    "    df['Class'] = np.where(df['Severity'] == 3, 1, 0)\n",
    "    df_c1 = df[df['Class'] != 0]\n",
    "    df_c0 = df[df['Class'] != 1]\n",
    "    df_c1 = df_c1.drop_duplicates()\n",
    "    df_c0 = df_c0.drop_duplicates()\n",
    "    df_c1.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/feat_eng_datasets_unbin/Feat_Eng_Merge/feat_eng_class3.csv\", columns = cols, index = False)\n",
    "    df_c0.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/feat_eng_datasets_unbin/Feat_Eng_Merge/feat_eng_class124_merge.csv\", columns = cols, index = False)\n",
    "\n",
    "    df['Class'] = np.where(df['Severity'] == 4, 1, 0)\n",
    "    df_c1 = df[df['Class'] != 0]\n",
    "    df_c0 = df[df['Class'] != 1]\n",
    "    df_c1 = df_c1.drop_duplicates()\n",
    "    df_c0 = df_c0.drop_duplicates()\n",
    "    df_c1.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/feat_eng_datasets_unbin/Feat_Eng_Merge/feat_eng_class4.csv\", columns = cols, index = False)\n",
    "    df_c0.to_csv(\"../Accident_Data_Preprocessing/Data_Cleaned/feat_eng_datasets_unbin/Feat_Eng_Merge/feat_eng_class123_merge.csv\", columns = cols, index = False)\n",
    "    \n",
    "    df = df.drop(columns = 'Class')\n",
    "    return df\n",
    "\n",
    "# DO NOT RUN WITH TEST DATA CLEANING\n",
    "#df = feat_eng_train_class_merge(df)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
